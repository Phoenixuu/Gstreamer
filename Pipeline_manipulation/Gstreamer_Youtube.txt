use Gstreamer as decoder/encoder, not a full pipeline
two ways:
1. Write a custom GStreamer element (hard)
2. Use appsrc and app sink (easy)

appsink is the sink, transfer data from pipeline to C++ code
appsrc is the source, supplies data from C++ into pipeline

APPSINK:
1. decode video file with decodebin
2. send raw BGR video to appsink
3. Display frames arriving to appsink via cv::imshow()

PIPELINE:
file src location = <..>!decodebin!videosink!appsink name = mysink max-buffers=2 sync=1 caps=video/x-raw,format=BGR

* caps=video/x-raw,format=BGR
* sync=1 for 1x (real-time speed) playback
* max-buffers=2 limits the queue size and thus RAM usage
* NOT use max-buffers=2 for audio + video (or multi branch) pipelines

USER THREADS:
1. Bus thread: process messages, exits on EOS or error
2. Appsink processing thread: pulls data packets from appsink and displays them with cv::imshow()

PROCESSING LOOP 1:
Check for EOS:
if(gst_app_sink_is_eos(GST_APP_SINK(data.sinkVideo))) break;

Wait for the sample (synchronous):
GstSample *sample = gst_app_sink_pull_sample(GST_APP_SINK(data.sinkVideo));

Get image witdth + heigt from sample caps:
GstCaps *caps = gst_sample_get_caps(sample);
GstStructure *s = gst_caps_get_structure(caps,0);
int imW, imH;
MY_ASSERT(gst_structure_get_int(s,"width",&imW);
MY_ASSERT(gst_structure_get_int(s,"height",&imH);

PROCESSING LOOP 2:
Buffer in GStreamer is a data packet, not queue
Get buffer with data, create a map to access it

GstBuffer *buffer = gst_sample_get_buffer(sample);
GstMapInfo m;
MY_ASSERT(gst_buffer_map(buffer, &m, GST_MAP_READ));

Wrap the BGR data with cv::Mat:
cv::MAT frame(imgH, imgW, CV_8UC3, (void *) m.data);

Free the memory:
gst_buffer_unmap(buffer,&m);
gst_sample_unref(sample);

